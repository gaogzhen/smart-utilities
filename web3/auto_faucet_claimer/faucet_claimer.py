# faucet_claimer.py
import asyncio
import json
import time
from datetime import datetime, timedelta
from crawl4ai import AsyncWebCrawler
from crawl4ai.async_configs import BrowserConfig
from config import FAUCET_TASKS, WALLET_ADDRESS, PROXY


class FaucetClaimer:
    def __init__(self):
        # åŠ è½½é¢†å–å†å²è®°å½•
        self.history_file = "claim_history.json"
        self.history = self.load_history()
        self.browser_config = BrowserConfig(
            headless=False,  # é¦–æ¬¡è°ƒè¯•è®¾ä¸ºFalseå¯ä»¥çœ‹åˆ°æµè§ˆå™¨æ“ä½œï¼Œç¨³å®šåæ”¹ä¸ºTrue
            proxy=PROXY if PROXY else None
        )

    def load_history(self):
        """åŠ è½½å†å²é¢†å–è®°å½•"""
        try:
            with open(self.history_file, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            return {}  # é¦–æ¬¡è¿è¡Œï¼Œå†å²è®°å½•ä¸ºç©º

    def save_history(self):
        """ä¿å­˜å†å²é¢†å–è®°å½•"""
        with open(self.history_file, 'w') as f:
            json.dump(self.history, f, indent=4)

    def can_claim(self, faucet_name):
        """æ£€æŸ¥æ˜¯å¦æ»¡è¶³24å°æ—¶é—´éš”"""
        if faucet_name not in self.history:
            return True
        last_claimed_str = self.history[faucet_name].get("last_claimed")
        if not last_claimed_str:
            return True

        last_claimed = datetime.fromisoformat(last_claimed_str)
        time_since_last = datetime.now() - last_claimed
        return time_since_last > timedelta(hours=24)

    async def execute_steps(self, crawler, steps, faucet_name):
        """æ‰§è¡Œé¢„å®šä¹‰çš„æ­¥éª¤åºåˆ—"""
        for step in steps:
            print(f"  -> æ­¥éª¤: {step.get('description', 'N/A')}")
            action = step.get("action")

            if action == "type":
                selector = step["selector"]
                value = step["value"]
                await crawler.page.type(selector, value)
                await asyncio.sleep(1)

            elif action == "click":
                selector = step["selector"]
                await crawler.page.click(selector)
                await asyncio.sleep(2)

            elif action == "select":
                selector = step["selector"]
                value = step["value"]
                await crawler.page.select_option(selector, value)
                await asyncio.sleep(1)

            elif action == "wait_for_text":
                text = step["text"]
                timeout = step.get("timeout", 10) * 1000  # è½¬æ¯«ç§’
                try:
                    await crawler.page.wait_for_selector(f"text={text}", timeout=timeout)
                except:
                    print(f"    è­¦å‘Š: æœªåœ¨é¡µé¢ä¸­æ‰¾åˆ°æ–‡æœ¬ '{text}'")

            elif action == "solve_captcha":
                # é‡åˆ°éªŒè¯ç æ—¶ï¼Œæš‚åœè„šæœ¬ï¼Œç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨æ“ä½œ
                print(f"\nâš ï¸  è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨è§£å†³éªŒè¯ç  ({faucet_name})...")
                print("    è§£å†³åï¼Œè¯·åœ¨æ§åˆ¶å°æŒ‰å›è½¦é”®ç»§ç»­...")
                input()  # é˜»å¡ï¼Œç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨æ“ä½œåæŒ‰å›è½¦
                await asyncio.sleep(3)

            await asyncio.sleep(1)  # æ­¥éª¤é—´åŸºç¡€é—´éš”

    def check_success(self, result, success_indicators):
        """æ ¹æ®é…ç½®çš„æˆåŠŸæŒ‡æ ‡ï¼Œåˆ¤æ–­é¢†å–æ˜¯å¦æˆåŠŸ"""
        html_lower = result.html.lower()
        for indicator in success_indicators:
            ind_type = indicator["type"]

            if ind_type == "text_in_page":
                if indicator["content"].lower() in html_lower:
                    return True

            elif ind_type == "element_present":
                # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºä½¿ç”¨crawleræ£€æŸ¥å…ƒç´ æ˜¯å¦å­˜åœ¨
                if indicator["selector"] in result.html:
                    return True
        return False

    async def claim_single_faucet(self, faucet):
        """é¢†å–å•ä¸ªæ°´é¾™å¤´"""
        faucet_name = faucet["name"]

        # 1. æ£€æŸ¥æ—¶é—´é—´éš”
        if not self.can_claim(faucet_name):
            wait_until = datetime.fromisoformat(self.history[faucet_name]["last_claimed"]) + timedelta(hours=24)
            print(f"â¸ï¸  è·³è¿‡ {faucet_name}ï¼Œä¸‹æ¬¡å¯é¢†å–æ—¶é—´: {wait_until.strftime('%Y-%m-%d %H:%M')}")
            return False

        print(f"\nğŸš€ å¼€å§‹å¤„ç†: {faucet_name}")

        # 2. ä½¿ç”¨Crawl4AIå¯åŠ¨æµè§ˆå™¨ä¼šè¯
        async with AsyncWebCrawler(config=self.browser_config) as crawler:
            try:
                # è®¿é—®é¡µé¢
                result = await crawler.arun(url=faucet["url"], wait_for=3000)
                if not result.success:
                    print(f"âŒ é¡µé¢åŠ è½½å¤±è´¥: {faucet_name}")
                    return False

                # 3. æ‰§è¡Œé¢„å®šä¹‰çš„é¢†å–æ­¥éª¤
                await self.execute_steps(crawler, faucet.get("steps", []), faucet_name)

                # 4. è·å–æœ€ç»ˆé¡µé¢ç»“æœï¼Œåˆ¤æ–­æ˜¯å¦æˆåŠŸ
                final_result = await crawler.arun(url=crawler.page.url, bypass_cache=True)

                if self.check_success(final_result, faucet.get("success_indicators", [])):
                    # é¢†å–æˆåŠŸï¼Œæ›´æ–°å†å²è®°å½•
                    self.history[faucet_name] = {
                        "last_claimed": datetime.now().isoformat(),
                        "network": faucet["network"]
                    }
                    self.save_history()
                    print(f"âœ… æˆåŠŸé¢†å– {faucet_name}!")
                    return True
                else:
                    print(f"âš ï¸  é¢†å–å¯èƒ½æœªæˆåŠŸ: {faucet_name} (æœªæ£€æµ‹åˆ°æˆåŠŸæ ‡å¿—)")
                    return False

            except Exception as e:
                print(f"âŒ å¤„ç† {faucet_name} æ—¶å‡ºé”™: {e}")
                return False
            finally:
                # ç¡®ä¿é¡µé¢å…³é—­
                await crawler.close()

    async def run(self):
        """éå†å¹¶å¤„ç†æ‰€æœ‰æ°´é¾™å¤´"""
        print(f"=== å¼€å§‹é¢†å–ä»»åŠ¡ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===")
        for faucet in FAUCET_TASKS:
            await self.claim_single_faucet(faucet)
            await asyncio.sleep(5)  # æ°´é¾™å¤´é—´é—´éš”ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
        print("=== é¢†å–ä»»åŠ¡ç»“æŸ ===\n")


async def main():
    claimer = FaucetClaimer()
    await claimer.run()


if __name__ == "__main__":
    asyncio.run(main())